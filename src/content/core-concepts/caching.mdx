---
title: 'Caching'
date: '2024-06-28'
description: 'Learn about the caching mechanisms in the Epic Stack.'
draft: false
type: 'core-concepts'
---

import GroupName from '../../components/docs/GroupName.astro'
import CodeBlock from '../../components/docs/CodeBlock.astro'

<GroupName>Core Concepts</GroupName>

# Caching

The Epic Stack comes with caching utilities and a management dashboard that allows you to view and clear your cache. There are two caches built into the Epic Stack:

1. **SQLite**: A separate database from the main application database, managed by LiteFS. This cache is replicated across all instances of your app and is suitable for long-lived cached values.

2. **LRU**: An in-memory cache used to store results of expensive queries or help deduplicate requests for data. This cache is not replicated across instances and will be cleared when your app is restarted, making it suitable for short-lived cached values.

Caching is intended for data that is expensive and/or slow to compute or retrieve. It can help avoid costs or rate limits associated with making requests to third parties.

## When to Use Caching

It's important to note that caching should not be the first solution to slowness issues. If you've got a slow query, look into optimizing it with database indexes before caching the results.

## Using the Cache

You typically won't interact directly with the caches. Instead, you'll use [`cachified`](https://www.npmjs.com/package/@epic-web/cachified), which provides a nice abstraction for cache management. The Epic Stack includes a small abstraction on top of it which allows you to pass `timings` to work seamlessly with the server timing utility.

Here's an example of how you might use cachified to cache events from a Tito API:

<CodeBlock
  code={`import { cachified, cache } from '#app/utils/cache.server.ts'
import { type Timings } from '#app/utils/timing.server.ts'

const eventSchema = z.object({/* the schema for events */})

export async function getScheduledEvents({
	timings,
}: {
	timings?: Timings
} = {}) {
	const scheduledEvents = await cachified({
		key: 'tito:scheduled-events',
		cache,
		timings,
		getFreshValue: () => {
			// do a fetch request to the tito API and stuff here
			return [
				/* the events you got from tito */
			]
		},
		checkValue: eventSchema.array(),
		// Time To Live (ttl) in milliseconds: the cached value is considered valid for 24 hours
		ttl: 1000 * 60 * 60 * 24,
		// Stale While Revalidate (swr) in milliseconds: if the cached value is less than 30 days
		// expired, return it while fetching a fresh value in the background
		staleWhileRevalidate: 1000 * 60 * 60 * 24 * 30,
	})
	return scheduledEvents
}`}
  lang='tsx'
/>

## How It Works

With this setup:

1. The first time you call `getScheduledEvents`, it will make a request to the Tito API and return the results. It will also cache the results in the `cache` (which is the SQLite cache).

2. On subsequent calls to `getScheduledEvents`:
   - If the cached value is less than 24 hours old, it will return the cached value.
   - If the cached value is between 24 hours and 30 days old, it will return the cached value and also make a request to the Tito API to update the cache.
   - If the cached value is more than 30 days old, it will wait for a fresh request to the Tito API and return the new value.

This approach significantly reduces the number of API requests and ensures users are never waiting for slow external API calls.

## Considerations

Every situation will require you to think through the implications of caching and acceptable staleness. The `ttl` and `staleWhileRevalidate` options provide levers to control this behavior based on your specific needs.

While this overview should be enough to get you started, caching is a complex topic that can warrant much more discussion and consideration in production applications.
